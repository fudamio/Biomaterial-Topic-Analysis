{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import check_output\n",
    "import csv\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = pd.read_csv('../output/result_regression.csv')\n",
    "specific_data = pd.read_csv('../output/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two datasets into one by key 'Topic_Year'\n",
    "final_data = group_data.merge(specific_data, how='right', on='Topic_Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del group_data\n",
    "del specific_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data after year 2000\n",
    "final_data = final_data[(final_data.PY >= 2004) & (final_data.PY < 2019)]\n",
    "final_data.drop(columns=['PY','Cluster_Topic'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data imputation by replacing median values\n",
    "missing_cols = []\n",
    "for col in final_data.columns:\n",
    "    if final_data[col].isnull().sum() != 0:\n",
    "        missing_cols.append(col)\n",
    "for missing_col in missing_cols:\n",
    "    final_data[missing_col].fillna(np.nanmedian(final_data[missing_col]), inplace=True)\n",
    "    \n",
    "final_data.drop(columns=['Year','Topic','Topic_Year','Growth_Rate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "final_data['Squeezed_Publisher'] = le.fit_transform(final_data['Squeezed_Publisher'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['PT'] = le.fit_transform(final_data['PT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final_data['Target'].values\n",
    "df = final_data.drop(['Target'],axis=1)\n",
    "X = df.values\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.10, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Ridge(alpha=1.0)\n",
    "clf.fit(Xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10139883084547364\n"
     ]
    }
   ],
   "source": [
    "print(sqrt(mean_squared_error(clf.predict(Xtest),ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Citation_feature                      0.001447\n",
       "Topic_num                            69.000000\n",
       "Five_Year_Percent                     0.245223\n",
       "Three_Year_Percent                    0.351598\n",
       "Sum_SJR                              62.657000\n",
       "Avg_SJR                               0.813727\n",
       "Growth_Rate                          -0.054795\n",
       "Citation_Growth_Rate                  0.487075\n",
       "Year_Growth_Rate                      0.160839\n",
       "Target                               -0.215634\n",
       "Avg_SJR_1                             1.020058\n",
       "Avg_SJR_2                             1.056329\n",
       "Avg_SJR_3                             1.127735\n",
       "Sum_SJR_1                            70.384000\n",
       "Sum_SJR_2                            77.112000\n",
       "Sum_SJR_3                           179.053000\n",
       "Review_AMT                            4.000000\n",
       "PT                                    1.000000\n",
       "PG                                    9.000000\n",
       "Have_Funding_Agency                   0.000000\n",
       "Author_count                          3.000000\n",
       "Funding_agency_count                  0.000000\n",
       "Squeezed_Publisher                    4.000000\n",
       "Contain_Top_All_authors               0.000000\n",
       "Contain_Top_All_funding_agencies      0.000000\n",
       "Count_of_top_funding_agency           0.000000\n",
       "Contain_Top_PU                        0.000000\n",
       "Name: 391, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.09464805e-02,  4.15479892e-04,  5.53620543e-01, -1.15413980e-01,\n",
       "       -6.04769139e-05,  2.64899773e-02, -1.46343727e-01, -2.34576915e-01,\n",
       "       -3.36276922e-01,  4.21164908e-01, -6.77581777e-02,  1.69328433e-03,\n",
       "       -2.51936261e-03,  3.88292719e-04,  1.31686354e-04,  3.90505182e-04,\n",
       "       -2.48843784e-05, -4.74917777e-03, -1.45814920e-04,  6.24937518e-04,\n",
       "       -3.97861165e-04,  7.99817768e-03, -4.35026768e-02,  3.49154584e-02,\n",
       "       -3.77075955e-04])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
